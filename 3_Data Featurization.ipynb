{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ecf6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d8581bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 1780938 nodes and 7550015 edges\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('data/train_orig.csv'):\n",
    "    train_graph=nx.read_edgelist('data/train_orig.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "    print(nx.info(train_graph))\n",
    "else:\n",
    "    print(\"Inorder to run this project, please follow the bello steps\")\n",
    "    print('Step 1: Run EDA.ipynb, atleast the first 3 cells if not full')\n",
    "    print('Step 2: Run full SplitData.ipynb or search the data folder for the required files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bd3401",
   "metadata": {},
   "source": [
    "##### Similarty measure used: Jaqard and Cosine\n",
    "$$\n",
    "  Jaquard Distance = \\frac{|X \\cap Y|}{|X \\cup Y|}\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daeba850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#helper function to calculate jaqard distance for followees\n",
    "def followees_jaqScore(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
    "                                    (len(set(train_graph.successors(a)).union(set(train_graph.successors(b)))))\n",
    "    except:\n",
    "        return 0\n",
    "    return sim\n",
    "\n",
    "#example test case\n",
    "print(followees_jaqScore(273084,1505602))\n",
    "print(followees_jaqScore(273084,1505602))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f34a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#helper function to calculate jaqard distance for followers\n",
    "def followers_jaqScore(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.predecessors(a))) == 0  | len(set(graph.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
    "                                 (len(set(train_graph.predecessors(a)).union(set(train_graph.predecessors(b)))))\n",
    "        return sim\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "#example test case\n",
    "print(followers_jaqScore(273084,470294))\n",
    "print(followees_jaqScore(669354,1635354))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee8b76",
   "metadata": {},
   "source": [
    "##### Cosine Similarity \n",
    "$$\n",
    "    Cosine Similarity = \\frac{|X \\cap Y|}{|X|\\cdot|Y|}\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2df7d84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#helper function to calculate cosine similarity for followers\n",
    "\n",
    "def followees_cosScore(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
    "                                    (math.sqrt(len(set(train_graph.successors(a)))*len((set(train_graph.successors(b))))))\n",
    "        return sim\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "#example test case\n",
    "print(followees_cosScore(273084,1505602))\n",
    "print(followees_cosScore(273084,1635354))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f490225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#for followees\n",
    "def preferential_followee(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
    "            return 0\n",
    "        preferential = (len(set(train_graph.successors(a)))*len((set(train_graph.successors(b)))))\n",
    "                                    \n",
    "        return preferential\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "print(preferential_followee(273083,1505602))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "811a150a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "def preferential_followers(a,b):\n",
    "    try:\n",
    "        \n",
    "        if len(set(train_graph.predecessors(a))) == 0  | len(set(train_graph.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        preferential = (len(set(train_graph.predecessors(a)))*len(set(train_graph.predecessors(b))))\n",
    "                                     \n",
    "        return preferential\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "print(preferential_followers(273084,1505602))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14dc6566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def followers_cosScore(a,b):\n",
    "    try:\n",
    "        \n",
    "        if len(set(train_graph.predecessors(a))) == 0  | len(set(train_graph.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
    "                                     (math.sqrt(len(set(train_graph.predecessors(a))))*(len(set(train_graph.predecessors(b)))))\n",
    "        return sim\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "#example test case\n",
    "print(followers_cosScore(2,470294))\n",
    "print(followers_cosScore(669354,1635354))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd75f54",
   "metadata": {},
   "source": [
    "##### Ranking Measures: Page Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cee42fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 1.657890853286788e-07\n",
      "max 2.799140908965827e-05\n",
      "mean 5.61501860254627e-07\n",
      "5.61501860254627e-07\n"
     ]
    }
   ],
   "source": [
    "#Calculate page rank\n",
    "if not os.path.isfile('data/page_rank.p'):\n",
    "    pr = nx.pagerank(train_graph, alpha=0.85)\n",
    "    pk.dump(pr,open('data/page_rank.p','wb'))\n",
    "else:\n",
    "    pr = pk.load(open('data/page_rank.p','rb'))\n",
    "\n",
    "print('min',pr[min(pr, key=pr.get)])\n",
    "print('max',pr[max(pr, key=pr.get)])\n",
    "print('mean',float(sum(pr.values())) / len(pr))\n",
    "\n",
    "#for inputing to nodes which are not there in Train data\n",
    "mean_pr = float(sum(pr.values())) / len(pr)\n",
    "print(mean_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e48345ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper function to compute shortest path:\n",
    "def compute_shortestPath(a,b):\n",
    "    p=-1\n",
    "    try:\n",
    "        if train_graph.has_edge(a,b):\n",
    "            train_graph.remove_edge(a,b)\n",
    "            p= nx.shortestPath(train_graph,source=a,target=b)\n",
    "            train_graph.add_edge(a,b)\n",
    "        else:\n",
    "            p= nx.shortestPath(train_graph,source=a,target=b)\n",
    "        return p\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "#test example cases\n",
    "compute_shortestPath(77697, 826021)\n",
    "compute_shortestPath(669354,1635354)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f78c6ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting weekly connected edges from graph \n",
    "weak_connec=list(nx.weakly_connected_components(train_graph))\n",
    "\n",
    "def belongs_toWeakConnec(a,b):\n",
    "    index = []\n",
    "    if train_graph.has_edge(b,a):\n",
    "        return 1\n",
    "    if train_graph.has_edge(a,b):\n",
    "            for i in weak_connec:\n",
    "                if a in i:\n",
    "                    index= i\n",
    "                    break\n",
    "            if (b in index):\n",
    "                train_graph.remove_edge(a,b)\n",
    "                if compute_shortestPath(a,b)==-1:\n",
    "                    train_graph.add_edge(a,b)\n",
    "                    return 0\n",
    "                else:\n",
    "                    train_graph.add_edge(a,b)\n",
    "                    return 1\n",
    "            else:\n",
    "                return 0\n",
    "    else:\n",
    "            for i in weak_connec:\n",
    "                if a in i:\n",
    "                    index= i\n",
    "                    break\n",
    "            if(b in index):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "#example test cases\n",
    "belongs_toWeakConnec(861, 1659750)\n",
    "belongs_toWeakConnec(669354,1635354)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b42a7431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adar_index(a,b):\n",
    "    val=0\n",
    "    try:\n",
    "        common=list(set(train_graph.successors(a)).intersection(set(train_graph.successors(b))))\n",
    "        if len(common)!=0:\n",
    "            for i in common:\n",
    "                val+=(1/np.log10(len(list(train_graph.predecessors(i)))))\n",
    "            return val\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "#example test case\n",
    "adar_index(1,189226)\n",
    "adar_index(669354,1635354)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02e3b0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def follows_back(a,b):\n",
    "    if train_graph.has_edge(b,a):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "follows_back(1,189226)\n",
    "follows_back(669354,1635354)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfc1d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_stage1(df_final):\n",
    "    num_followers_s=[]\n",
    "    num_followees_s=[]\n",
    "    num_followers_d=[]\n",
    "    num_followees_d=[]\n",
    "    inter_followers=[]\n",
    "    inter_followees=[]\n",
    "    for i,row in df_final.iterrows():\n",
    "        try:\n",
    "            s1=set(train_graph.predecessors(row['source_node']))\n",
    "            s2=set(train_graph.successors(row['source_node']))\n",
    "        except:\n",
    "            s1 = set()\n",
    "            s2 = set()\n",
    "        try:\n",
    "            d1=set(train_graph.predecessors(row['destination_node']))\n",
    "            d2=set(train_graph.successors(row['destination_node']))\n",
    "        except:\n",
    "            d1 = set()\n",
    "            d2 = set()\n",
    "        num_followers_s.append(len(s1))\n",
    "        num_followees_s.append(len(s2))\n",
    "\n",
    "        num_followers_d.append(len(d1))\n",
    "        num_followees_d.append(len(d2))\n",
    "\n",
    "        inter_followers.append(len(s1.intersection(d1)))\n",
    "        inter_followees.append(len(s2.intersection(d2)))\n",
    "    \n",
    "    return num_followers_s, num_followers_d, num_followees_s, num_followees_d, inter_followers, inter_followees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5df5c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd(x, S,dictionary):\n",
    "    try:\n",
    "        z = dictionary[x]\n",
    "        return S[z]\n",
    "    except:\n",
    "        return [0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4355c2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 0.0007313184369994846\n",
      "max 0.0033831594632843507\n",
      "mean 0.0007483399997557072\n",
      "0.0007483399997557072\n"
     ]
    }
   ],
   "source": [
    "# Katz Centrality:\n",
    "if not os.path.isfile('data/katz.p'):\n",
    "    katz = nx.katz.katz_centrality(train_graph,alpha=0.005,beta=1)\n",
    "    pk.dump(katz,open('data/katz.p','wb'))\n",
    "else:\n",
    "    katz = pk.load(open('data/katz.p','rb'))\n",
    "\n",
    "print('min',katz[min(katz, key=katz.get)])\n",
    "print('max',katz[max(katz, key=katz.get)])\n",
    "print('mean',float(sum(katz.values())) / len(katz))\n",
    "\n",
    "mean_katz = float(sum(katz.values())) / len(katz)\n",
    "print(mean_katz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "340a6a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min -9.967983755663483e-21\n",
      "max 0.004838592143483775\n",
      "mean 5.61501860252738e-07\n"
     ]
    }
   ],
   "source": [
    "# Hits Score\n",
    "\n",
    "if not os.path.isfile('data/hits.p'):\n",
    "    hits = nx.hits(train_graph, max_iter=100, tol=1e-08, nstart=None, normalized=True)\n",
    "    pk.dump(hits,open('data/hits.p','wb'))\n",
    "else:\n",
    "    hits = pk.load(open('data/hits.p','rb'))\n",
    "\n",
    "print('min',hits[0][min(hits[0], key=hits[0].get)])\n",
    "print('max',hits[0][max(hits[0], key=hits[0].get)])\n",
    "print('mean',float(sum(hits[0].values())) / len(hits[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6313a651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the train data file: 15100028\n",
      "Number of rows we are going to elimiate in train data are 15000028\n",
      "Number of rows in the test data file: 3775006\n",
      "Number of rows we are going to elimiate in test data are 3725006\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('data/train_orig.csv'):\n",
    "    filename = \"data/train_orig.csv\"\n",
    "    n_train =  15100028\n",
    "    s = 100000\n",
    "    skip_train = sorted(random.sample(range(1,n_train+1),n_train-s))\n",
    "    \n",
    "if os.path.isfile('data/test_orig.csv'):\n",
    "    filename = \"data/test_orig.csv\"\n",
    "    n_test = 3775006\n",
    "    s = 50000\n",
    "    skip_test = sorted(random.sample(range(1,n_test+1),n_test-s))\n",
    "\n",
    "print(\"Number of rows in the train data file:\", n_train)\n",
    "print(\"Number of rows we are going to elimiate in train data are\",len(skip_train))\n",
    "print(\"Number of rows in the test data file:\", n_test)\n",
    "print(\"Number of rows we are going to elimiate in test data are\",len(skip_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb33c8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix size  (100002, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>destination_node</th>\n",
       "      <th>indicator_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365363</td>\n",
       "      <td>425182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1746765</td>\n",
       "      <td>501746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117292</td>\n",
       "      <td>783587</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162833</td>\n",
       "      <td>1385156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1818705</td>\n",
       "      <td>1699250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_node  destination_node  indicator_link\n",
       "0       365363            425182               1\n",
       "1      1746765            501746               1\n",
       "2       117292            783587               1\n",
       "3       162833           1385156               1\n",
       "4      1818705           1699250               1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_train = pd.read_csv('data/train_x.csv', skiprows=skip_train, names=['source_node', 'destination_node'])\n",
    "df_final_train['indicator_link'] = pd.read_csv('data/train_y.csv', skiprows=skip_train, names=['indicator_link'])\n",
    "print(\"Train matrix size \",df_final_train.shape)\n",
    "df_final_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b69bc082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test matrix size  (50002, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>destination_node</th>\n",
       "      <th>indicator_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1696056</td>\n",
       "      <td>1165625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>398614</td>\n",
       "      <td>946454</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>719206</td>\n",
       "      <td>276747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>551027</td>\n",
       "      <td>1787160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>484859</td>\n",
       "      <td>1056642</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_node  destination_node  indicator_link\n",
       "0      1696056           1165625               1\n",
       "1       398614            946454               1\n",
       "2       719206            276747               1\n",
       "3       551027           1787160               1\n",
       "4       484859           1056642               1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_test = pd.read_csv('data/test_x.csv', skiprows=skip_test, names=['source_node', 'destination_node'])\n",
    "df_final_test['indicator_link'] = pd.read_csv('data/test_y.csv', skiprows=skip_test, names=['indicator_link'])\n",
    "print(\"Test matrix size \",df_final_test.shape)\n",
    "df_final_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d9df9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a set of features\n",
    "\n",
    "if not os.path.isfile('data/storage_sample_stage1.h5'):\n",
    "    df_final_train['jaccard_followers'] = df_final_train.apply(lambda row:followers_jaqScore\n",
    "                                                               (row['source_node'],row['destination_node']),axis=1)\n",
    "    \n",
    "    df_final_test['jaccard_followers'] = df_final_test.apply(lambda row:followers_jaqScore\n",
    "                                                             (row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    df_final_train['jaccard_followees'] = df_final_train.apply(lambda row:followees_jaqScore\n",
    "                                                               (row['source_node'],row['destination_node']),axis=1)\n",
    "    \n",
    "    df_final_test['jaccard_followees'] = df_final_test.apply(lambda row:followees_jaqScore\n",
    "                                                             (row['source_node'],row['destination_node']),axis=1)\n",
    "    \n",
    "    df_final_train['cosine_followers'] = df_final_train.apply(lambda row:followers_cosScore\n",
    "                                                              (row['source_node'],row['destination_node']),axis=1)\n",
    "    \n",
    "    df_final_test['cosine_followers'] = df_final_test.apply(lambda row:followers_cosScore\n",
    "                                                            (row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    df_final_train['cosine_followees'] = df_final_train.apply(lambda row:followees_cosScore\n",
    "                                                              (row['source_node'],row['destination_node']),axis=1)\n",
    "    \n",
    "    df_final_test['cosine_followees'] = df_final_test.apply(lambda row:followees_cosScore\n",
    "                                                            (row['source_node'],row['destination_node']),axis=1)\n",
    "    \n",
    "    \n",
    "    df_final_train['num_followers_s'], df_final_train['num_followers_d'], \\\n",
    "    df_final_train['num_followees_s'], df_final_train['num_followees_d'], \\\n",
    "    df_final_train['inter_followers'], df_final_train['inter_followees']= compute_features_stage1(df_final_train)\n",
    "    \n",
    "    \n",
    "    df_final_test['num_followers_s'], df_final_test['num_followers_d'], \\\n",
    "    df_final_test['num_followees_s'], df_final_test['num_followees_d'], \\\n",
    "    df_final_test['inter_followers'], df_final_test['inter_followees']= compute_features_stage1(df_final_test)\n",
    "    \n",
    "    \n",
    "    hdf = pd.HDFStore('data/storage_sample_stage1.h5')\n",
    "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "    hdf.close()\n",
    "else:\n",
    "    df_final_train = pd.read_hdf('data/storage_sample_stage1.h5', 'train_df',mode='r')\n",
    "    df_final_test = pd.read_hdf('data/storage_sample_stage1.h5', 'test_df',mode='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dba6c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new set of features\n",
    "\n",
    "if not os.path.isfile('data/storage_sample_stage2.h5'):\n",
    "    #mapping adar index on train\n",
    "    df_final_train['adar_index'] = df_final_train.apply(lambda row: adar_index(row['source_node'],row['destination_node']),axis=1)\n",
    "    #mapping adar index on test\n",
    "    df_final_test['adar_index'] = df_final_test.apply(lambda row: adar_index(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------\n",
    "    #mapping followback or not on train\n",
    "    df_final_train['follows_back'] = df_final_train.apply(lambda row: follows_back(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    #mapping followback or not on test\n",
    "    df_final_test['follows_back'] = df_final_test.apply(lambda row: follows_back(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------\n",
    "    #mapping same component of wcc or not on train\n",
    "    df_final_train['same_comp'] = df_final_train.apply(lambda row: belongs_toWeakConnec(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    ##mapping same component of wcc or not on train\n",
    "    df_final_test['same_comp'] = df_final_test.apply(lambda row: belongs_toWeakConnec(row['source_node'],row['destination_node']),axis=1)\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------\n",
    "    #mapping shortest path on train \n",
    "    df_final_train['shortest_path'] = df_final_train.apply(lambda row: compute_shortestPath(row['source_node'],row['destination_node']),axis=1)\n",
    "    #mapping shortest path on test\n",
    "    df_final_test['shortest_path'] = df_final_test.apply(lambda row: compute_shortestPath(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    hdf = pd.HDFStore('data/storage_sample_stage2.h5')\n",
    "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "    hdf.close()\n",
    "else:\n",
    "    df_final_train = pd.read_hdf('data/storage_sample_stage2.h5', 'train_df',mode='r')\n",
    "    df_final_test = pd.read_hdf('data/storage_sample_stage2.h5', 'test_df',mode='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cde31b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1780938/1780938 [00:09<00:00, 191643.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Weight Features for source and destination of each link\n",
    "Weight_in = {}\n",
    "Weight_out = {}\n",
    "for i in  tqdm(train_graph.nodes()):\n",
    "    s1=set(train_graph.predecessors(i))\n",
    "    w_in = 1.0/(np.sqrt(1+len(s1)))\n",
    "    Weight_in[i]=w_in\n",
    "    \n",
    "    s2=set(train_graph.successors(i))\n",
    "    w_out = 1.0/(np.sqrt(1+len(s2)))\n",
    "    Weight_out[i]=w_out\n",
    "    \n",
    "#for imputing with mean\n",
    "mean_weight_in = np.mean(list(Weight_in.values()))\n",
    "mean_weight_out = np.mean(list(Weight_out.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c440969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new set of features\n",
    "if not os.path.isfile('data/storage_sample_stage3.h5'):\n",
    "    #mapping to pandas train\n",
    "    df_final_train['weight_in'] = df_final_train.destination_node.apply(lambda x: Weight_in.get(x,mean_weight_in))\n",
    "    df_final_train['weight_out'] = df_final_train.source_node.apply(lambda x: Weight_out.get(x,mean_weight_out))\n",
    "\n",
    "    #mapping to pandas test\n",
    "    df_final_test['weight_in'] = df_final_test.destination_node.apply(lambda x: Weight_in.get(x,mean_weight_in))\n",
    "    df_final_test['weight_out'] = df_final_test.source_node.apply(lambda x: Weight_out.get(x,mean_weight_out))\n",
    "\n",
    "\n",
    "    #some features engineerings on the in and out weights\n",
    "    df_final_train['weight_f1'] = df_final_train.weight_in + df_final_train.weight_out\n",
    "    df_final_train['weight_f2'] = df_final_train.weight_in * df_final_train.weight_out\n",
    "    df_final_train['weight_f3'] = (2*df_final_train.weight_in + 1*df_final_train.weight_out)\n",
    "    df_final_train['weight_f4'] = (1*df_final_train.weight_in + 2*df_final_train.weight_out)\n",
    "\n",
    "    #some features engineerings on the in and out weights\n",
    "    df_final_test['weight_f1'] = df_final_test.weight_in + df_final_test.weight_out\n",
    "    df_final_test['weight_f2'] = df_final_test.weight_in * df_final_test.weight_out\n",
    "    df_final_test['weight_f3'] = (2*df_final_test.weight_in + 1*df_final_test.weight_out)\n",
    "    df_final_test['weight_f4'] = (1*df_final_test.weight_in + 2*df_final_test.weight_out)\n",
    "    \n",
    "    df_final_train['page_rank_s'] = df_final_train.source_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "    df_final_train['page_rank_d'] = df_final_train.destination_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "\n",
    "    df_final_test['page_rank_s'] = df_final_test.source_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "    df_final_test['page_rank_d'] = df_final_test.destination_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "    #================================================================================\n",
    "\n",
    "    #Katz centrality score for source and destination in Train and test\n",
    "    #if anything not there in train graph then adding mean katz score\n",
    "    df_final_train['katz_s'] = df_final_train.source_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "    df_final_train['katz_d'] = df_final_train.destination_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "\n",
    "    df_final_test['katz_s'] = df_final_test.source_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "    df_final_test['katz_d'] = df_final_test.destination_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "    #================================================================================\n",
    "\n",
    "    #Hits algorithm score for source and destination in Train and test\n",
    "    #if anything not there in train graph then adding 0\n",
    "    df_final_train['hubs_s'] = df_final_train.source_node.apply(lambda x: hits[0].get(x,0))\n",
    "    df_final_train['hubs_d'] = df_final_train.destination_node.apply(lambda x: hits[0].get(x,0))\n",
    "\n",
    "    df_final_test['hubs_s'] = df_final_test.source_node.apply(lambda x: hits[0].get(x,0))\n",
    "    df_final_test['hubs_d'] = df_final_test.destination_node.apply(lambda x: hits[0].get(x,0))\n",
    "    #================================================================================\n",
    "\n",
    "    #Hits algorithm score for source and destination in Train and Test\n",
    "    #if anything not there in train graph then adding 0\n",
    "    df_final_train['authorities_s'] = df_final_train.source_node.apply(lambda x: hits[1].get(x,0))\n",
    "    df_final_train['authorities_d'] = df_final_train.destination_node.apply(lambda x: hits[1].get(x,0))\n",
    "\n",
    "    df_final_test['authorities_s'] = df_final_test.source_node.apply(lambda x: hits[1].get(x,0))\n",
    "    df_final_test['authorities_d'] = df_final_test.destination_node.apply(lambda x: hits[1].get(x,0))\n",
    "    #================================================================================\n",
    "\n",
    "    hdf = pd.HDFStore('data/storage_sample_stage3.h5')\n",
    "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "    hdf.close()\n",
    "else:\n",
    "    df_final_train = pd.read_hdf('data/storage_sample_stage3.h5', 'train_df',mode='r')\n",
    "    df_final_test = pd.read_hdf('data/storage_sample_stage3.h5', 'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d291570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix Shape (1780938, 1780938)\n",
      "U Shape (1780938, 6)\n",
      "V Shape (6, 1780938)\n",
      "s Shape (6,)\n"
     ]
    }
   ],
   "source": [
    "# Adding new set of features\n",
    "#for svd features to get feature vector creating a dict nde val and inedx in svd vector\n",
    "sadj_col = sorted(train_graph.nodes())\n",
    "sadj_dict = { val:idx for idx,val in enumerate(sadj_col)}\n",
    "\n",
    "Adj = nx.adjacency_matrix(train_graph,nodelist=sorted(train_graph.nodes())).asfptype()\n",
    "\n",
    "U, s, V = svds(Adj, k = 6)\n",
    "print('Adjacency matrix Shape',Adj.shape)\n",
    "print('U Shape',U.shape)\n",
    "print('V Shape',V.shape)\n",
    "print('s Shape',s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "802c1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('data/storage_sample_stage4.h5'):\n",
    "    #===================================================================================================\n",
    "    \n",
    "    df_final_train[['svd_u_s_1', 'svd_u_s_2','svd_u_s_3', 'svd_u_s_4', 'svd_u_s_5', 'svd_u_s_6']] = \\\n",
    "    df_final_train.source_node.apply(lambda x: svd(x, U,sadj_dict)).apply(pd.Series)\n",
    "    \n",
    "    df_final_train[['svd_u_d_1', 'svd_u_d_2', 'svd_u_d_3', 'svd_u_d_4', 'svd_u_d_5','svd_u_d_6']] = \\\n",
    "    df_final_train.destination_node.apply(lambda x: svd(x, U,sadj_dict)).apply(pd.Series)\n",
    "    #===================================================================================================\n",
    "    \n",
    "    df_final_train[['svd_v_s_1','svd_v_s_2', 'svd_v_s_3', 'svd_v_s_4', 'svd_v_s_5', 'svd_v_s_6',]] = \\\n",
    "    df_final_train.source_node.apply(lambda x: svd(x, V.T,sadj_dict)).apply(pd.Series)\n",
    "\n",
    "    df_final_train[['svd_v_d_1', 'svd_v_d_2', 'svd_v_d_3', 'svd_v_d_4', 'svd_v_d_5','svd_v_d_6']] = \\\n",
    "    df_final_train.destination_node.apply(lambda x: svd(x, V.T,sadj_dict)).apply(pd.Series)\n",
    "    #===================================================================================================\n",
    "    \n",
    "    df_final_test[['svd_u_s_1', 'svd_u_s_2','svd_u_s_3', 'svd_u_s_4', 'svd_u_s_5', 'svd_u_s_6']] = \\\n",
    "    df_final_test.source_node.apply(lambda x: svd(x, U,sadj_dict)).apply(pd.Series)\n",
    "    \n",
    "    df_final_test[['svd_u_d_1', 'svd_u_d_2', 'svd_u_d_3', 'svd_u_d_4', 'svd_u_d_5','svd_u_d_6']] = \\\n",
    "    df_final_test.destination_node.apply(lambda x: svd(x, U,sadj_dict)).apply(pd.Series)\n",
    "\n",
    "    #===================================================================================================\n",
    "    \n",
    "    df_final_test[['svd_v_s_1','svd_v_s_2', 'svd_v_s_3', 'svd_v_s_4', 'svd_v_s_5', 'svd_v_s_6',]] = \\\n",
    "    df_final_test.source_node.apply(lambda x: svd(x, V.T,sadj_dict)).apply(pd.Series)\n",
    "\n",
    "    df_final_test[['svd_v_d_1', 'svd_v_d_2', 'svd_v_d_3', 'svd_v_d_4', 'svd_v_d_5','svd_v_d_6']] = \\\n",
    "    df_final_test.destination_node.apply(lambda x: svd(x, V.T,sadj_dict)).apply(pd.Series)\n",
    "    #===================================================================================================\n",
    "\n",
    "    hdf = pd.HDFStore('data/storage_sample_stage4.h5')\n",
    "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "    hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25342457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding few more features\n",
    "if not os.path.isfile('data/storage_sample_stage5.h5'):\n",
    "    \n",
    "         #===================================================================================================\n",
    "\n",
    "        #mapping preferential_followers to train and test data\n",
    "        df_final_train['preferential_followers'] = df_final_train.apply(lambda row:\n",
    "                                                preferential_followers(row['source_node'],row['destination_node']),axis=1)\n",
    "        df_final_test['preferential_followers'] = df_final_test.apply(lambda row:\n",
    "                                                preferential_followers(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "        #===================================================================================================\n",
    "\n",
    "        #mapping preferential_followee to train and test data\n",
    "        df_final_train['preferential_followee'] = df_final_train.apply(lambda row:\n",
    "                                                preferential_followee(row['source_node'],row['destination_node']),axis=1)\n",
    "        df_final_test['preferential_followee'] = df_final_test.apply(lambda row:\n",
    "                                                preferential_followee(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "\n",
    "        #===================================================================================================\n",
    "\n",
    "        \n",
    "\n",
    "        df_final_train['svd_dot_u'] = df_final_train['svd_u_s_1']*df_final_train['svd_u_d_1']\\\n",
    "        + df_final_train['svd_u_s_2']*df_final_train['svd_u_d_2']\\\n",
    "        + df_final_train['svd_u_s_3']*df_final_train['svd_u_d_3']\\\n",
    "        + df_final_train['svd_u_s_4']*df_final_train['svd_u_d_4']\\\n",
    "        + df_final_train['svd_u_s_5']*df_final_train['svd_u_d_5']\\\n",
    "        + df_final_train['svd_u_s_6']*df_final_train['svd_u_d_6']\n",
    "\n",
    "        #===================================================================================================\n",
    "\n",
    "         \n",
    "\n",
    "\n",
    "\n",
    "        df_final_train['svd_dot_v'] =  df_final_train['svd_v_s_1']*df_final_train['svd_v_d_1']\\\n",
    "        + df_final_train['svd_v_s_2']*df_final_train['svd_v_d_2']\\\n",
    "        + df_final_train['svd_v_s_3']*df_final_train['svd_v_d_3']\\\n",
    "        + df_final_train['svd_v_s_4']*df_final_train['svd_v_d_4']\\\n",
    "        + df_final_train['svd_v_s_5']*df_final_train['svd_v_d_5']\\\n",
    "        + df_final_train['svd_v_s_6']*df_final_train['svd_v_d_6']\n",
    "\n",
    "        #===================================================================================================\n",
    " \n",
    "\n",
    "        df_final_test['svd_dot_u'] = df_final_test['svd_u_s_1']*df_final_test['svd_u_d_1']\\\n",
    "        + df_final_test['svd_u_s_2']*df_final_test['svd_u_d_2']\\\n",
    "        + df_final_test['svd_u_s_3']*df_final_test['svd_u_d_3']\\\n",
    "        + df_final_test['svd_u_s_4']*df_final_test['svd_u_d_4']\\\n",
    "        + df_final_test['svd_u_s_5']*df_final_test['svd_u_d_5']\\\n",
    "        + df_final_test['svd_u_s_6']*df_final_test['svd_u_d_6']\n",
    "        #===================================================================================================\n",
    "\n",
    "        df_final_test['svd_dot_v']  = df_final_test['svd_v_s_1']*df_final_test['svd_v_d_1']\\\n",
    "        + df_final_test['svd_v_s_2']*df_final_test['svd_v_d_2']\\\n",
    "        + df_final_test['svd_v_s_3']*df_final_test['svd_v_d_3']\\\n",
    "        + df_final_test['svd_v_s_4']*df_final_test['svd_v_d_4']\\\n",
    "        + df_final_test['svd_v_s_5']*df_final_test['svd_v_d_5']\\\n",
    "        + df_final_test['svd_v_s_6']*df_final_test['svd_v_d_6']\n",
    "\n",
    "        #===================================================================================================\n",
    "\n",
    "        hdf = pd.HDFStore('data/storage_sample_stage5.h5')\n",
    "        hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "        hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "        hdf.close()\n",
    "else:\n",
    "        df_final_train = pd.read_hdf('data/storage_sample_stage5.h5', 'train_df',mode='r')\n",
    "        df_final_test = pd.read_hdf('data/storage_sample_stage5.h5', 'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac14762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
